{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXaOgl2gLc+v/6N6ciKWlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krakalus/RAG-Work/blob/main/CRM_Agentic_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LMHSMcG3KXs",
        "outputId": "25ca449b-bdba-41e4-cbea-09648c0253bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               name              company                         title  \\\n",
            "0          John Doe        TechCorp Inc.                           CEO   \n",
            "1        Jane Smith   Innovate Solutions            Marketing Director   \n",
            "2         Bob Jones   Global Enterprises                 Sales Manager   \n",
            "3       Alice Brown       FutureTech LLC                           CTO   \n",
            "4     Charlie Davis     Elite Consulting                   VP of Sales   \n",
            "5       Emma Wilson    Dynamic Marketing                           CMO   \n",
            "6       Michael Lee   Strategic Partners             Account Executive   \n",
            "7      Sarah Taylor   Visionary Ventures  Business Development Manager   \n",
            "8       David Clark    Premier Analytics                  Data Analyst   \n",
            "9        Lisa Adams          Nexus Group               Product Manager   \n",
            "10       Tom Harris     Quantum Dynamics                       Founder   \n",
            "11     Rachel Green         Synergy Labs            Head of Operations   \n",
            "12        Mike Ross  Pinnacle Strategies             Senior Consultant   \n",
            "13    Donna Paulsen     Apex Innovations           Director of Finance   \n",
            "14   Harvey Specter      Summit Partners                           CIO   \n",
            "15       Louis Litt     Vertex Solutions                    Head of HR   \n",
            "16  Jessica Pearson         Horizon Tech               General Counsel   \n",
            "17    Alex Williams        Catalyst Corp         Chief Revenue Officer   \n",
            "\n",
            "                 industry  company_size  estimated_revenue        lead_source  \\\n",
            "0              Technology           500           50000000            Webinar   \n",
            "1               Marketing           200           20000000           Referral   \n",
            "2           Manufacturing          1000          100000000         Trade Show   \n",
            "3              Technology           150           15000000      Inbound Email   \n",
            "4              Consulting           300           30000000       Social Media   \n",
            "5               Marketing           250           25000000        Partnership   \n",
            "6                 Finance           400           40000000          Cold Call   \n",
            "7              Technology           180           18000000   Content Download   \n",
            "8               Analytics           220           22000000              Event   \n",
            "9                Software           350           35000000           LinkedIn   \n",
            "10           Tech Startup            50            5000000         Google Ads   \n",
            "11                Biotech           120           12000000     Email Campaign   \n",
            "12  Management Consulting           280           28000000   Partner Referral   \n",
            "13                Finance            90            9000000     Organic Search   \n",
            "14            IT Services           600           60000000         Conference   \n",
            "15                HR Tech           140           14000000       Demo Request   \n",
            "16             Legal Tech           320           32000000          Blog Read   \n",
            "17     Revenue Management           450           45000000  Newsletter Signup   \n",
            "\n",
            "   engagement_level last_activity_date           status  lead_score  \n",
            "0              High         10/01/2025     VIP Prospect          95  \n",
            "1            Medium         09/28/2025             Lead          75  \n",
            "2               Low         08/15/2025         Prospect          40  \n",
            "3              High         09/30/2025         VIP Lead          90  \n",
            "4              High         10/02/2025     VIP Prospect          98  \n",
            "5            Medium         09/25/2025             Lead          80  \n",
            "6               Low         07/20/2025         Prospect          35  \n",
            "7              High         09/29/2025         VIP Lead          85  \n",
            "8            Medium         10/01/2025             Lead          70  \n",
            "9              High         09/27/2025     VIP Prospect          92  \n",
            "10             High         10/03/2025  High-Value Lead          88  \n",
            "11           Medium         09/26/2025         Prospect          65  \n",
            "12              Low         08/10/2025         VIP Lead          45  \n",
            "13             High         09/24/2025             Lead          82  \n",
            "14           Medium         10/01/2025     VIP Prospect          96  \n",
            "15             High         09/22/2025  High-Value Lead          78  \n",
            "16              Low         08/05/2025         Prospect          50  \n",
            "17           Medium         09/23/2025         VIP Lead          89  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Enhanced CRM dataset for Agentic AI Lead Scoring & Prioritization\n",
        "# Use case: Autonomous CRM Agent that retrieves leads, scores them based on fit (demographics, behavior),\n",
        "# reasons on priority (e.g., high-value VIP prospects with recent engagement), and suggests actions\n",
        "# like personalized outreach, lead routing, or Salesforce workflow triggers.\n",
        "# This dataset supports multi-step agentic flow: Retrieve → Score → Reason → Act (e.g., simulate update lead status).\n",
        "# Fields inspired by Salesforce lead schemas: identity (name, company), descriptive (title, industry, size),\n",
        "# quantitative (revenue, score), behavioral (engagement level, last activity), status (Prospect, Lead, VIP).\n",
        "\n",
        "data = {\n",
        "    \"name\": [\n",
        "        \"John Doe\", \"Jane Smith\", \"Bob Jones\", \"Alice Brown\", \"Charlie Davis\", \"Emma Wilson\", \"Michael Lee\",\n",
        "        \"Sarah Taylor\", \"David Clark\", \"Lisa Adams\", \"Tom Harris\", \"Rachel Green\", \"Mike Ross\", \"Donna Paulsen\",\n",
        "        \"Harvey Specter\", \"Louis Litt\", \"Jessica Pearson\", \"Alex Williams\"\n",
        "    ],\n",
        "    \"company\": [\n",
        "        \"TechCorp Inc.\", \"Innovate Solutions\", \"Global Enterprises\", \"FutureTech LLC\", \"Elite Consulting\",\n",
        "        \"Dynamic Marketing\", \"Strategic Partners\", \"Visionary Ventures\", \"Premier Analytics\", \"Nexus Group\",\n",
        "        \"Quantum Dynamics\", \"Synergy Labs\", \"Pinnacle Strategies\", \"Apex Innovations\", \"Summit Partners\",\n",
        "        \"Vertex Solutions\", \"Horizon Tech\", \"Catalyst Corp\"\n",
        "    ],\n",
        "    \"title\": [\n",
        "        \"CEO\", \"Marketing Director\", \"Sales Manager\", \"CTO\", \"VP of Sales\", \"CMO\", \"Account Executive\",\n",
        "        \"Business Development Manager\", \"Data Analyst\", \"Product Manager\", \"Founder\", \"Head of Operations\",\n",
        "        \"Senior Consultant\", \"Director of Finance\", \"CIO\", \"Head of HR\", \"General Counsel\", \"Chief Revenue Officer\"\n",
        "    ],\n",
        "    \"industry\": [\n",
        "        \"Technology\", \"Marketing\", \"Manufacturing\", \"Technology\", \"Consulting\", \"Marketing\", \"Finance\",\n",
        "        \"Technology\", \"Analytics\", \"Software\", \"Tech Startup\", \"Biotech\", \"Management Consulting\", \"Finance\",\n",
        "        \"IT Services\", \"HR Tech\", \"Legal Tech\", \"Revenue Management\"\n",
        "    ],\n",
        "    \"company_size\": [500, 200, 1000, 150, 300, 250, 400, 180, 220, 350, 50, 120, 280, 90, 600, 140, 320, 450],\n",
        "    \"estimated_revenue\": [50000000, 20000000, 100000000, 15000000, 30000000, 25000000, 40000000, 18000000, 22000000, 35000000, 5000000, 12000000, 28000000, 9000000, 60000000, 14000000, 32000000, 45000000],\n",
        "    \"lead_source\": [\n",
        "        \"Webinar\", \"Referral\", \"Trade Show\", \"Inbound Email\", \"Social Media\", \"Partnership\", \"Cold Call\",\n",
        "        \"Content Download\", \"Event\", \"LinkedIn\", \"Google Ads\", \"Email Campaign\", \"Partner Referral\",\n",
        "        \"Organic Search\", \"Conference\", \"Demo Request\", \"Blog Read\", \"Newsletter Signup\"\n",
        "    ],\n",
        "    \"engagement_level\": [\"High\", \"Medium\", \"Low\", \"High\", \"High\", \"Medium\", \"Low\", \"High\", \"Medium\", \"High\", \"High\", \"Medium\", \"Low\", \"High\", \"Medium\", \"High\", \"Low\", \"Medium\"],\n",
        "    \"last_activity_date\": [\n",
        "        \"10/01/2025\", \"09/28/2025\", \"08/15/2025\", \"09/30/2025\", \"10/02/2025\", \"09/25/2025\", \"07/20/2025\",\n",
        "        \"09/29/2025\", \"10/01/2025\", \"09/27/2025\", \"10/03/2025\", \"09/26/2025\", \"08/10/2025\", \"09/24/2025\",\n",
        "        \"10/01/2025\", \"09/22/2025\", \"08/05/2025\", \"09/23/2025\"\n",
        "    ],\n",
        "    \"status\": [\n",
        "        \"VIP Prospect\", \"Lead\", \"Prospect\", \"VIP Lead\", \"VIP Prospect\", \"Lead\", \"Prospect\", \"VIP Lead\",\n",
        "        \"Lead\", \"VIP Prospect\", \"High-Value Lead\", \"Prospect\", \"VIP Lead\", \"Lead\", \"VIP Prospect\",\n",
        "        \"High-Value Lead\", \"Prospect\", \"VIP Lead\"\n",
        "    ],\n",
        "    \"lead_score\": [95, 75, 40, 90, 98, 80, 35, 85, 70, 92, 88, 65, 45, 82, 96, 78, 50, 89]  # AI-predicted score (0-100)\n",
        "}\n",
        "\n",
        "# Create DataFrame and save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"crm_leads_enhanced.csv\", index=False)\n",
        "\n",
        "# Display the DataFrame to verify\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kyJTRlG3m66",
        "outputId": "8974280f-2d2b-437e-c0c2-1ac0d78d03ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.12.0 langchain-community-0.3.30 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "nuGGvMMl4HtZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize NVIDIA API client\n",
        "import os\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"API_KEY\"),  # Replace with your NVIDIA API key\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "5mxSSZ0_4M81"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load your existing CRM data from the CSV (already created in Colab)\n",
        "df = pd.read_csv(\"crm_leads_enhanced.csv\")"
      ],
      "metadata": {
        "id": "TJuRXP-04Q63"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Generate embeddings for CRM data\n",
        "texts = df.apply(lambda x: f\"{x['name']}, {x['status']}, score:{x['lead_score']}, engagement:{x['engagement_level']}, last_activity:{x['last_activity_date']}\", axis=1).tolist()\n",
        "response = client.embeddings.create(\n",
        "    input=texts,\n",
        "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
        "    encoding_format=\"base64\",\n",
        "    extra_body={\"input_type\": \"query\", \"truncate\": \"END\"}\n",
        ")"
      ],
      "metadata": {
        "id": "m4grMaec4ZXd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode base64 embeddings to float arrays\n",
        "embeddings = [np.frombuffer(base64.b64decode(emb.embedding)) for emb in response.data]"
      ],
      "metadata": {
        "id": "m7vlghIn4cey"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Store embeddings in FAISS\n",
        "# Create Document objects with string page_content\n",
        "documents = [Document(page_content=text) for text in texts]\n",
        "\n",
        "# Define a dummy Embeddings class to use precomputed embeddings\n",
        "from langchain.embeddings.base import Embeddings\n",
        "class DummyEmbeddings(Embeddings):\n",
        "    def __init__(self, precomputed_embeddings):\n",
        "        self.precomputed_embeddings = precomputed_embeddings\n",
        "    def embed_documents(self, texts):\n",
        "        return self.precomputed_embeddings\n",
        "    def embed_query(self, text):\n",
        "        return self.precomputed_embeddings[0]  # Return first embedding for query (simplified)\n",
        "\n",
        "# Use FAISS with precomputed embeddings and dummy embedding object\n",
        "embedding_obj = DummyEmbeddings(embeddings)\n",
        "vector_store = FAISS.from_embeddings(\n",
        "    text_embeddings=[(doc.page_content, emb) for doc, emb in zip(documents, embeddings)],\n",
        "    embedding=embedding_obj\n",
        ")"
      ],
      "metadata": {
        "id": "86K4rYzp4gFo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Gradio UI for Agentic RAG\n",
        "!pip install gradio -q\n",
        "\n",
        "import gradio as gr\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def get_agentic_response(query):\n",
        "    # Reuse RAG logic from Cell 9\n",
        "    retriever = vector_store.as_retriever()\n",
        "    retrieved_docs = retriever.invoke(query)\n",
        "    print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
        "\n",
        "    def score_lead(doc):\n",
        "        content = doc.page_content\n",
        "        score = int(''.join(filter(str.isdigit, content.split('score:')[1].split(',')[0]))) if 'score:' in content else 0\n",
        "        is_vip = any(status in content for status in [\"VIP Prospect\", \"VIP Lead\", \"High-Value Lead\"])\n",
        "        date = content.split('last_activity:')[1].split(',')[0] if 'last_activity:' in content else \"01/01/2020\"\n",
        "        return score > 80 and is_vip, score, date\n",
        "\n",
        "    high_priority_leads = [doc for doc in retrieved_docs if score_lead(doc)[0]]\n",
        "    leads_with_scores = [(doc, score_lead(doc)[1], score_lead(doc)[2]) for doc in high_priority_leads]\n",
        "    leads_with_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)  # Score desc, date asc\n",
        "\n",
        "    if not high_priority_leads:\n",
        "        return \"No high-priority leads identified.\", \"\", \"\"\n",
        "\n",
        "    context = \"\\n\".join([f\"{doc.page_content} (Score: {score}, Date: {date})\" for doc, score, date in leads_with_scores])\n",
        "    prompt = f\"\"\"You are an autonomous CRM agent. Based on this lead data, follow these steps:\n",
        "    1. Assess priority: Rank leads by score (highest first), then by latest last_activity_date.\n",
        "    2. Reason: Determine if outreach is needed (score > 80 and VIP/High-Value status justify action).\n",
        "    3. Act: Suggest 2-3 unique Salesforce actions per lead, tailored to their industry or title.\n",
        "\n",
        "    Lead Data:\n",
        "    {context}\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Provide output as: 'Priority Ranking: [list]\\nReasoning: [summary]\\nActions: [action list]'\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"nvidia/llama-3.1-nemotron-nano-8b-v1\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        output = response.choices[0].message.content\n",
        "        # Split output into sections\n",
        "        ranking = output.split('\\nReasoning:')[0].replace('Priority Ranking:', '').strip()\n",
        "        reasoning = output.split('\\nReasoning:')[1].split('\\nActions:')[0].strip()\n",
        "        actions = output.split('\\nActions:')[1].strip()\n",
        "        return ranking, reasoning, actions\n",
        "    except Exception as e:\n",
        "        return f\"API error: {e}\", \"\", \"\"\n",
        "\n",
        "# Create enhanced Gradio interface with custom styling\n",
        "with gr.Blocks(title=\"CRM Lead Prioritization Agent\", theme=gr.themes.Soft()) as interface:\n",
        "    gr.Markdown(\"# CRM Lead Prioritization Agent\\nPowered by NVIDIA NIM & AWS\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            query_input = gr.Textbox(label=\"Enter Query\", placeholder=\"e.g., 'Identify and prioritize high-value leads for Salesforce outreach'\", lines=3)\n",
        "            submit_btn = gr.Button(\"Analyze Leads\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            ranking_output = gr.Textbox(label=\"Priority Ranking\", interactive=False, lines=5)\n",
        "            reasoning_output = gr.Textbox(label=\"Reasoning\", interactive=False, lines=5)\n",
        "            actions_output = gr.Textbox(label=\"Actions\", interactive=False, lines=8)\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=get_agentic_response,\n",
        "        inputs=query_input,\n",
        "        outputs=[ranking_output, reasoning_output, actions_output]\n",
        "    )\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "srmt2LZQ89VZ",
        "outputId": "33a97bc6-29a1-4715-f78f-f26803b64050"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96be294c9a191fb4b2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://96be294c9a191fb4b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}